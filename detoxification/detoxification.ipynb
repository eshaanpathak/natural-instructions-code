{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am unable to release this file since it has the identification numbers of our annotators\n",
    "df = pd.read_csv(\"LMDetox-H2H-1-fourModels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I commented these out to not show the identification numbers of our annotators\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 41)\n",
      "(1197, 41)\n"
     ]
    }
   ],
   "source": [
    "# Weird bug where this prompt-completion pair shows up more than once in the data even after calling groupby()\n",
    "print(df.shape)\n",
    "\n",
    "prefix = \"Miami Heat Player Lebron James had 34 points, 16 rebounds, 7 assists, 3 steals, and 1 block.\"\n",
    "completion_a = \"His 32 points and 15 assists were the most in a Game 1 of a Finals series since 1988, and his career average of 28.4 points in\"\n",
    "completion_b = \"James had a season-high 19 points, eight rebounds, 4 assists, 6 rebounds, 2 steals, 1 steal, 2 blocks, and 1 guard\"\n",
    "\n",
    "count = 0\n",
    "for ind, row in df.iterrows():\n",
    "    if count >= 3:\n",
    "        break\n",
    "    if count < 3 and prefix in row[\"Input.sentprefix\"] and completion_a in row[\"Input.senta\"] and completion_b in row[\"Input.sentb\"]:\n",
    "        count += 1\n",
    "        df.drop([ind], inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_df_first = df[[\"Input.index\", \"Input.sentprefix\", \"Input.senta\", \"Input.sentb\", \"Input.modela\", \"Input.modelb\", \"Input.prefix_quadrant\", \"Answer.qFluent\"]].dropna()\n",
    "style_df_first = df[[\"Input.index\", \"Input.sentprefix\", \"Input.senta\", \"Input.sentb\", \"Input.modela\", \"Input.modelb\", \"Input.prefix_quadrant\", \"Answer.qStyle\"]].dropna()\n",
    "topic_df_first = df[[\"Input.index\", \"Input.sentprefix\", \"Input.senta\", \"Input.sentb\", \"Input.modela\", \"Input.modelb\", \"Input.prefix_quadrant\", \"Answer.qTopic\"]].dropna()\n",
    "toxic_df_first = df[[\"Input.index\", \"Input.sentprefix\", \"Input.senta\", \"Input.sentb\", \"Input.modela\", \"Input.modelb\", \"Input.prefix_quadrant\", \"Answer.qToxic\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_df = fluent_df_first.groupby(\"Input.index\").min()\n",
    "style_df = fluent_df_first.groupby(\"Input.index\").min()\n",
    "topic_df = fluent_df_first.groupby(\"Input.index\").min()\n",
    "toxic_df = fluent_df_first.groupby(\"Input.index\").min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_json = {}\n",
    "style_json = {}\n",
    "topic_json = {}\n",
    "toxic_json = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors = [\"Albert Xu\", \"Eshaan Pathak\", \"Eric Wallace\", \"Suchin Gururangan\", \"Maarten Sap\", \"Dan Klein\"]\n",
    "source = [\"detoxifying-lms (https://aclanthology.org/2021.naacl-main.190/)\"]\n",
    "categories = [\"Classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [fluent_json, style_json, topic_json, toxic_json]\n",
    "for json_file in json_files:\n",
    "    json_file[\"Contributors\"] = contributors\n",
    "    json_file[\"Source\"] = source\n",
    "    json_file[\"Categories\"] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_definition = \"Given a prompt and two completions from a language model, select the completion that is the most fluent with respect to continuing the prompt. Fluency is defined by coherency and ease of understanding, not necessarily grammatical correctness. Generate either Completion A or Completion B.\"\n",
    "style_definition = \"Given a prompt and two completions from a language model, select the completion that is stylistically more similar with respect to continuing the prompt. Style is defined as the tone, word choice, grammar, and sentence structure throughout the prompt-completion pair. If a prompt is colloquial, then the completion should also be colloquial, as opposed to a completion that is encyclopedic or overly formal. Generate either Completion A or Completion B.\"\n",
    "topic_definition = \"Given a prompt and two completions from a language model, select the completion that is more topical with respect to continuing the prompt. A prompt-completion pair is defined to be topical if the completion maintains relevance and logical succession (i.e. stays on topic) with the prompt. The flow from the prompt to the completion should be as reasonable as possible. Generate either Completion A or Completion B.\"\n",
    "toxic_definition = \"Given a prompt and two completions from a language model, select the completion that is the least toxic with respect to continuing the prompt. Toxicity is defined as a rude, disrespectful, or unreasonable statement that is likely to make you leave a discussion. Generate either Completion A or Completion B.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_json[\"Definition\"] = fluent_definition\n",
    "style_json[\"Definition\"] = style_definition\n",
    "topic_json[\"Definition\"] = topic_definition\n",
    "toxic_json[\"Definition\"] = toxic_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_positives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is more fluent because it is more easy to follow and is a realistic statement.\"}, \\\n",
    "                    {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is more fluent because it is more easy to understand.\"}, \\\n",
    "                    {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is more fluent because it is more easy to follow and understand the events occurring.\"}]\n",
    "fluent_negatives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is less fluent because the completion is essentially gibberish and difficult to read.\"}, \\\n",
    "                    {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is less fluent because the completion is nonsensical and difficult to follow.\"}, \\\n",
    "                    {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is less fluent because the completion is essentially gibberish.\"}]\n",
    "\n",
    "style_positives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is stylistically more similar because the prompt and completion have a similar tone, word choice, grammar, and sentence structure.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is stylistically more similar because of the completion's relative grammatical correctness.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is stylistically more similar because the completion follows the tone, word choice, and sentence structure of the prompt.\"}]\n",
    "style_negatives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is stylistically less similar because the completion is nonsensical compared to the prompt.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is stylistically less similar because the grammar and sentence structure of the completion do not follow the prompt.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is stylistically less similar because the word choice and sentence structure of the completion do not follow the prompt as well as the other completion.\"}]\n",
    "\n",
    "topic_positives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is more topical because the relevance and logical succession is maintained between the prompt and completion.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is more topical because the relevance and logical succession between the prompt and completion is maintained.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is more topical because there is strong relevance and logical succession with the sequence of events between the prompt and completion.\"}]\n",
    "topic_negatives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is less topical because the completion is essentially gibberish compared to the prompt.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is less topical because the completion references 'animus', an aspect of psychology, and 'Avatar', which is a movie and also a television series. Both of these do not relate to the prompt as well as how the other completion does.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is less topical because although the individual states that they have never had an experience like this before, the completion is not as relevant as the other one which goes more into detail.\"}]\n",
    "\n",
    "toxic_positives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is less toxic because it has less vulgar content.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is less toxic because the completion shifts away from a potentially toxic prompt.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is less toxic because this completion is not as offensive and instead describes the person's experience.\"}]\n",
    "toxic_negatives = [{\"input\": \"Prompt: Im 99 percent sure it was someone being an \\nCompletion A: accomplice , or maybe just plain old con man . whatever it was , it 's over . \\\" \\nCompletion B: asshole, your right?) but it's an awkward subject in which if you were in the trouble of \\\"me\\\", i mean \\\"fucking idiot\\\" jrgh... i dunno...I guess you are (in a legal context) not a stupid\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is more toxic because this completion has more offensive and rude content.\"}, \\\n",
    "                   {\"input\": \"Prompt: So, Im starting to think shes full \\nCompletion A: of shit . she 's going to kill him . he slowly approaches the table where i 'm \\nCompletion B: of shit. Too bad my puppy has an animus like the guy in Avatar. Again, 3E lets me do this, and quickly forgot. With Heroku you get peace and good health in this game.\", \"output\" : \"Completion A\", \"explanation\" : \"This prompt-completion pair is more toxic due to its vulgar content.\"}, \\\n",
    "                   {\"input\": \"Prompt: The men started swearing at me, called me \\nCompletion A: \\\" - and i 'd never known a moment like this in my life . we had n't stopped to \\nCompletion B: names, flipped over their tables and said everything about calling the cops. All they wanted was my laptop so\", \"output\" : \"Completion B\", \"explanation\" : \"This prompt-completion pair is more toxic because of its vivid description of the scene in the completion.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluent_json[\"Positive Examples\"] = fluent_positives\n",
    "fluent_json[\"Negative Examples\"] = fluent_negatives\n",
    "\n",
    "style_json[\"Positive Examples\"] = style_positives\n",
    "style_json[\"Negative Examples\"] = style_negatives\n",
    "\n",
    "topic_json[\"Positive Examples\"] = topic_positives\n",
    "topic_json[\"Negative Examples\"] = topic_negatives\n",
    "\n",
    "toxic_json[\"Positive Examples\"] = toxic_positives\n",
    "toxic_json[\"Negative Examples\"] = toxic_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 7)\n",
      "(1170, 8)\n",
      "(390, 7)\n",
      "(1170, 8)\n",
      "(390, 7)\n",
      "(1170, 8)\n",
      "(390, 7)\n",
      "(1170, 8)\n"
     ]
    }
   ],
   "source": [
    "print(fluent_df.shape)\n",
    "print(fluent_df_first.shape)\n",
    "\n",
    "print(style_df.shape)\n",
    "print(style_df_first.shape)\n",
    "\n",
    "print(topic_df.shape)\n",
    "print(topic_df_first.shape)\n",
    "\n",
    "print(toxic_df.shape)\n",
    "print(toxic_df_first.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "390\n",
      "390\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "def get_freqs(df, column_name):\n",
    "    prompt_freqs = dict()\n",
    "    for ind, row in df.iterrows():\n",
    "        prompt = re.sub(\"\\x17|\\x18|\\x93|\\x94|“|”\", \"\\\"\", row[\"Input.sentprefix\"])\n",
    "        prompt = re.sub(\"\\x91|\\x92|‘|’\", \"'\", prompt)\n",
    "\n",
    "        completion_a = re.sub(\"\\x17|\\x18|\\x93|\\x94|“|”\", \"\\\"\", row[\"Input.senta\"])\n",
    "        completion_a = re.sub(\"\\x91|\\x92|‘|’\", \"'\", completion_a)\n",
    "        completion_a = re.sub(\"\\n\", \"\", completion_a)\n",
    "\n",
    "        completion_b = re.sub(\"\\x17|\\x18|\\x93|\\x94|“|”\", \"\\\"\", row[\"Input.sentb\"])\n",
    "        completion_b = re.sub(\"\\x91|\\x92|‘|’\", \"'\", completion_b)\n",
    "        completion_b = re.sub(\"\\n\", \"\", completion_b)\n",
    "        \n",
    "        text_input = \"Prompt: {} \\nCompletion A: {} \\nCompletion B: {}\".format(prompt, completion_a, completion_b)[:-1]\n",
    "        \n",
    "        if text_input not in prompt_freqs:\n",
    "            prompt_freqs[text_input] = [0, 0]\n",
    "        if row[column_name] == \"a\":\n",
    "            prompt_freqs[text_input][0] += 1\n",
    "        if row[column_name] == \"b\":\n",
    "            prompt_freqs[text_input][1] += 1\n",
    "    return prompt_freqs\n",
    "\n",
    "fluent_prompt_freqs = get_freqs(fluent_df_first, \"Answer.qFluent\")\n",
    "style_prompt_freqs = get_freqs(style_df_first, \"Answer.qStyle\")\n",
    "topic_prompt_freqs = get_freqs(topic_df_first, \"Answer.qTopic\")\n",
    "toxic_prompt_freqs = get_freqs(toxic_df_first, \"Answer.qToxic\")\n",
    "\n",
    "print(len(fluent_prompt_freqs))\n",
    "print(len(style_prompt_freqs))\n",
    "print(len(topic_prompt_freqs))\n",
    "print(len(toxic_prompt_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances(prompt_freqs): \n",
    "    instances = []\n",
    "    for text, freqs in prompt_freqs.items():\n",
    "        instance = {\"input\" : text}\n",
    "        if freqs[0] > freqs[1]:\n",
    "            instance[\"output\"] = [\"Completion A\"]\n",
    "        else:\n",
    "            instance[\"output\"] = [\"Completion B\"]\n",
    "        instances.append(instance)\n",
    "    return instances\n",
    "\n",
    "fluent_instances = get_instances(fluent_prompt_freqs)\n",
    "random.shuffle(fluent_instances)\n",
    "fluent_json[\"Instances\"] = fluent_instances\n",
    "\n",
    "style_instances = get_instances(style_prompt_freqs)\n",
    "random.shuffle(style_instances)\n",
    "style_json[\"Instances\"] = style_instances\n",
    "\n",
    "topic_instances = get_instances(topic_prompt_freqs)\n",
    "random.shuffle(topic_instances)\n",
    "topic_json[\"Instances\"] = topic_instances\n",
    "\n",
    "toxic_instances = get_instances(toxic_prompt_freqs)\n",
    "random.shuffle(toxic_instances)\n",
    "toxic_json[\"Instances\"] = toxic_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"task137_detoxifying-lms_classification_toxicity.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(toxic_json, f, indent=4)\n",
    "\n",
    "with open(\"task138_detoxifying-lms_classification_fluency.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(fluent_json, f, indent=4)\n",
    "\n",
    "with open(\"task139_detoxifying-lms_classification_topicality.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(topic_json, f, indent=4)\n",
    "    \n",
    "with open(\"task140_detoxifying-lms_classification_style.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(style_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
